# Réimportation des bibliothèques après la réinitialisation de l'état d'exécution
import os
import time
import webbrowser
import speech_recognition as sr
import pyttsx3

class AdvancedAI_OperatingSystem:
    def __init__(self):
        self.memory = {}  # Stockage des interactions
        self.task_list = []  # Gestion des tâches en cours
        self.voice_engine = pyttsx3.init()  # Initialisation de la synthèse vocale

    def speak(self, text):
        """Prononce une réponse à l'utilisateur."""
        self.voice_engine.say(text)
        self.voice_engine.runAndWait()

    def listen_command(self):
        """Écoute une commande vocale et la retourne en texte."""
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Parlez...")
            self.speak("Je vous écoute.")
            recognizer.adjust_for_ambient_noise(source)
            try:
                audio = recognizer.listen(source)
                command = recognizer.recognize_google(audio, language="fr-FR")
                print(f"Vous avez dit : {command}")
                return command
            except sr.UnknownValueError:
                self.speak("Désolé, je n'ai pas compris.")
                return None
            except sr.RequestError:
                self.speak("Erreur de connexion à Google Speech API.")
                return None

    def execute_command(self, command):
        """Interprète et exécute une commande donnée."""
        command = command.lower()
        
        if "ouvrir navigateur" in command:
            webbrowser.open("https://www.google.com")
            return "Navigateur ouvert."
        
        elif "heure" in command:
            return f"Heure actuelle : {time.strftime('%H:%M:%S')}"
        
        elif "mémoriser" in command:
            key_value = command.replace("mémoriser ", "").split("=")
            if len(key_value) == 2:
                self.memory[key_value[0].strip()] = key_value[1].strip()
                return f"Information mémorisée : {key_value[0]} = {key_value[1]}"
        
        elif "rappelle-moi" in command:
            key = command.replace("rappelle-moi ", "").strip()
            return self.memory.get(key, "Aucune information trouvée.")
        
        elif "ajouter tâche" in command:
            task = command.replace("ajouter tâche ", "").strip()
            self.task_list.append(task)
            return f"Tâche ajoutée : {task}"
        
        elif "lister tâches" in command:
            return "\n".join(self.task_list) if self.task_list else "Aucune tâche en cours."

        elif "ouvrir fichier" in command:
            filename = command.replace("ouvrir fichier ", "").strip()
            if os.path.exists(filename):
                os.system(f"open {filename}" if os.name == "posix" else f"start {filename}")
                return f"Ouverture de {filename}."
            else:
                return "Fichier non trouvé."

        else:
            return "Commande non reconnue."

    def run(self):
        """Boucle principale d'interaction avec reconnaissance vocale."""
        self.speak("Système d'exploitation IA - Luméa Jarvis v0.2 prêt à fonctionner.")
        return "Système Luméa Jarvis v0.2 initialisé avec reconnaissance vocale et gestion de tâches."

# Création d'une instance avancée du système d'exploitation IA
os_ai_advanced = AdvancedAI_OperatingSystem()
os_ai_advanced.run()
import os
import time
import webbrowser
import speech_recognition as sr
import pyttsx3
import requests
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from textblob import TextBlob  # Pour l'analyse du ton émotionnel

class LuméaOS:
    def __init__(self):
        self.memory = {}  # Stockage des interactions pour apprentissage
        self.task_list = []  # Gestion des tâches
        self.voice_engine = pyttsx3.init()  # Synthèse vocale
        self.vectorizer = TfidfVectorizer()  # Vectorisation des textes
        self.classifier = KNeighborsClassifier(n_neighbors=3)  # Algorithme de classification
        
        # Base d'apprentissage initiale
        self.training_data = {
            "ouvrir navigateur": "web",
            "donne-moi l'heure": "time",
            "ajouter une tâche": "add_task",
            "mémorise ceci": "memory",
            "rappelle-moi quelque chose": "recall",
            "cherche sur internet": "search",
            "contrôle un appareil": "device_control",
            "quelle est la météo": "weather",
            "montre-moi les actualités": "news"
        }
        self.train_ai()

    def speak(self, text):
        """Prononce une réponse à l'utilisateur."""
        self.voice_engine.say(text)
        self.voice_engine.runAndWait()

    def listen_command(self):
        """Écoute une commande vocale et la retourne en texte."""
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            print("Parlez...")
            self.speak("Je vous écoute.")
            recognizer.adjust_for_ambient_noise(source)
            try:
                audio = recognizer.listen(source)
                command = recognizer.recognize_google(audio, language="fr-FR")
                print(f"Vous avez dit : {command}")
                return command
            except sr.UnknownValueError:
                self.speak("Désolé, je n'ai pas compris.")
                return None
            except sr.RequestError:
                self.speak("Erreur de connexion à Google Speech API.")
                return None

    def analyze_emotion(self, text):
        """Analyse l'émotion de l'utilisateur à partir du texte."""
        analysis = TextBlob(text)
        sentiment = analysis.sentiment.polarity
        if sentiment > 0.2:
            return "positif"
        elif sentiment < -0.2:
            return "négatif"
        else:
            return "neutre"

    def train_ai(self):
        """Entraîne l'IA sur des commandes de base."""
        X_train = list(self.training_data.keys())
        y_train = list(self.training_data.values())
        X_vectors = self.vectorizer.fit_transform(X_train)
        self.classifier.fit(X_vectors, y_train)

    def predict_command(self, command):
        """Prédit la catégorie d'une commande en fonction de l'apprentissage."""
        command_vector = self.vectorizer.transform([command])
        return self.classifier.predict(command_vector)[0]

    def execute_command(self, command):
        """Interprète et exécute une commande donnée."""
        command = command.lower()
        predicted_action = self.predict_command(command)

        # Analyse des émotions
        emotion = self.analyze_emotion(command)
        if emotion == "négatif":
            self.speak("Je ressens que quelque chose ne va pas. Comment puis-je vous aider ?")

        if predicted_action == "web":
            webbrowser.open("https://www.google.com")
            return "Navigateur ouvert."

        elif predicted_action == "time":
            return f"Heure actuelle : {time.strftime('%H:%M:%S')}"

        elif predicted_action == "add_task":
            task = command.replace("ajouter une tâche ", "").strip()
            self.task_list.append(task)
            return f"Tâche ajoutée : {task}"

        elif predicted_action == "memory":
            key_value = command.replace("mémorise ceci ", "").split("=")
            if len(key_value) == 2:
                self.memory[key_value[0].strip()] = key_value[1].strip()
                return f"Information mémorisée : {key_value[0]} = {key_value[1]}"

        elif predicted_action == "recall":
            key = command.replace("rappelle-moi ", "").strip()
            return self.memory.get(key, "Aucune information trouvée.")

        elif predicted_action == "search":
            search_query = command.replace("cherche sur internet ", "").strip()
            response = requests.get(f"https://www.google.com/search?q={search_query}")
            return f"Recherche en cours : {search_query}"

        elif predicted_action == "device_control":
            return "Connexion à un appareil en cours... (Fonctionnalité à implémenter)"

        elif predicted_action == "weather":
            response = requests.get("https://wttr.in/?format=%C+%t")  # API simple météo
            return f"Météo actuelle : {response.text}"

        elif predicted_action == "news":
            news_response = requests.get("https://newsapi.org/v2/top-headlines?country=fr&apiKey=YOUR_NEWSAPI_KEY")
            if news_response.status_code == 200:
                news_data = news_response.json()
                headlines = [article["title"] for article in news_data["articles"][:3]]
                return f"Voici les trois principales actualités :\n" + "\n".join(headlines)
            return "Impossible de récupérer les actualités."

        else:
            return "Commande non reconnue."

    def run(self):
        """Boucle principale d'interaction avec reconnaissance vocale et apprentissage."""
        self.speak("Système d'exploitation IA - Luméa v0.4 prêt à fonctionner avec reconnaissance émotionnelle et connexions avancées.")
        while True:
            print("\nAttente de commande (Texte ou Parole)...")
            command = input("Entrez une commande ou dites 'écoute' pour parler : ").strip()

            if command.lower() == "écoute":
                command = self.listen_command()

            if command:
                if command.lower() in ["quitter", "exit", "stop"]:
                    self.speak("Arrêt du système. À bientôt.")
                    print("Arrêt du système...")
                    break

                response = self.execute_command(command)
                print(f"> {response}")
                self.speak(response)

# Démarrer le système IA avancé
lumea_os = LuméaOS()
lumea_os.run()
